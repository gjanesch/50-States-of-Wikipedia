{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from itertools import compress\n",
    "import json    #Used to pretty-print dictionaries\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WIKI_BASE = \"https://en.wikipedia.org/wiki/Template:\"\n",
    "STATE_LIST = [\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\"Connecticut\",\n",
    "              \"Delaware\",\"Florida\",\"Georgia_(U.S._state)\",\"Hawaii\",\"Idaho\",\"Illinois\",\"Indiana\",\n",
    "              \"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\"Massachusetts\",\n",
    "              \"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\"Nebraska\",\"Nevada\",\n",
    "              \"New_Hampshire\",\"New_Jersey\",\"New_Mexico\",\"New_York\",\"North_Carolina\",\"North_Dakota\",\n",
    "              \"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\"Rhode_Island\",\"South_Carolina\",\n",
    "              \"South_Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\"Vermont\",\"Virginia\",\"Washington\",\n",
    "              \"West_Virginia\",\"Wisconsin\",\"Wyoming\"]\n",
    "\n",
    "\n",
    "state_template_urls = [WIKI_BASE + S.strip() for S in STATE_LIST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# template is inside first <div> with class=\"navbox\" inside <div> with class=\"mw-parser-output\"\n",
    "def get_state_template(state_template_url):\n",
    "    \"\"\"Grabs the HTML of the state template.\"\"\"\n",
    "    raw_page = requests.get(state_template_url)\n",
    "    soup = BeautifulSoup(raw_page.text, \"lxml\")\n",
    "    state_template = soup.find(\"div\", attrs={'class':'mw-parser-output'})\n",
    "    state_template = state_template.find(\"div\", attrs={'class':'navbox'})\n",
    "    return state_template\n",
    "\n",
    "state_templates = {stu:get_state_template(stu) for stu in state_template_urls}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_links(table_row):\n",
    "    \"\"\"Collects the all text highlighted by a link in a template's table row.\n",
    "    A few cases of tables in table rows are accounted for via recursion. Also\n",
    "    eliminates links to pages that don't exist.\n",
    "    \"\"\"\n",
    "    if table_row.find_all(\"table\") != []:\n",
    "        state_links = []\n",
    "        trs = table_row.find(\"table\").find_all(\"tr\", recursive = False)\n",
    "        for tr in trs:\n",
    "            state_links.extend(get_links(tr))\n",
    "        return state_links\n",
    "    else:\n",
    "        state_links = table_row.find_all(\"li\")\n",
    "        link_names = [sl.text for sl in state_links]\n",
    "        does_link_exist = ['redlink' not in sl.a['href'] for sl in state_links]\n",
    "        return compress(link_names, does_link_exist)\n",
    "\n",
    "# Use collections.defaultdict in order to add new group/link names\n",
    "# without throwing errors\n",
    "group_dict = collections.defaultdict(list)\n",
    "link_dict = collections.defaultdict(list)\n",
    "for k,v in state_templates.items():\n",
    "    \n",
    "    table_rows = v.find(\"table\").find_all(\"tr\", recursive = False)[2:]\n",
    "    \n",
    "    for tr in table_rows:\n",
    "        group = tr.find(\"th\").text\n",
    "        group = re.sub(\"\\n\\n\", \" \", group)\n",
    "        group_dict[group].append(k)\n",
    "        \n",
    "        state_links = get_links(tr)\n",
    "        for sl in state_links:\n",
    "            link_dict[sl].append(k)\n",
    "\n",
    "#print({k:len(v) for k,v in group_dict.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"Geography\": 42,\n",
      "   \"People\": 35,\n",
      "   \"Crime\": 44,\n",
      "   \"Culture\": 47,\n",
      "   \"Demographics\": 49,\n",
      "   \"Economy\": 49,\n",
      "   \"Education\": 49,\n",
      "   \"Politics\": 44,\n",
      "   \"Washington\": 30,\n",
      "   \"History\": 42,\n",
      "   \"Government\": 35,\n",
      "   \"Tourist attractions\": 40\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps({k:len(v) for k,v in link_dict.items() if len(v) >= 30}, indent = 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
